{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project_Preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuhZue_GLJJw",
        "outputId": "653fea68-3bc3-4c22-ffd0-291b5894eaf0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM5jgdYzLdm0"
      },
      "source": [
        "import collections\n",
        "import pathlib\n",
        "import re\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2qtHHNrqCEc",
        "outputId": "f2e5b304-5e7e-43ec-8d8f-7d46980e6f4c"
      },
      "source": [
        "pip install tensorflow-text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b2/2dbd90b93913afd07e6101b8b84327c401c394e60141c1e98590038060b3/tensorflow_text-2.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.4,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (0.35.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.33.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (2.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (2.10.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.4.1)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow<2.4,>=2.3.0->tensorflow-text) (50.3.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (2020.11.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (2.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text) (0.4.8)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QyetirKLnsV"
      },
      "source": [
        "import tensorflow_text as tf_text\n",
        "import pandas as pd \n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QesUdiBYabeY"
      },
      "source": [
        "## When Size of Input data is not too Large: Create Dataframe Using Pandas and then proceed "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju1KsH3Kv8pd"
      },
      "source": [
        "## We use multiple lists and form the final dataframe from dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtqmD7yQFZHX",
        "outputId": "ae95ece1-4380-417c-84c0-1a4d1228c278"
      },
      "source": [
        "path = \"/gdrive/MyDrive/Text_Summarizer/Data/\"\n",
        "\n",
        "# Writing For loops for each directory level and extracting file names\n",
        "# as section, sub-section and lecture topics \n",
        "\n",
        "# I expect thsi to take a while so we will time the code \n",
        "import time \n",
        "start = time.time()\n",
        "\n",
        "\n",
        "course_list = []\n",
        "section_list = []\n",
        "sub_section_list = []\n",
        "lec_list = []\n",
        "transcript_list = []\n",
        "\n",
        "\n",
        "for course in os.listdir(path):\n",
        "  print(course)\n",
        "  course_path = os.path.join(path, course)\n",
        "  if os.path.isdir(course_path):\n",
        "    for section in os.listdir(course_path):\n",
        "      section_path = os.path.join(course_path, section)\n",
        "      if os.path.isdir(section_path):\n",
        "        #print(section)\n",
        "        sec_match = re.search(\"([0-9]{2}_)([0-9A-Za-z-]*)\", section)\n",
        "        week_number = sec_match.group(1).strip(\"_\")\n",
        "        section_title = sec_match.group(2)\n",
        "        \n",
        "        # Iterate over sub-sections \n",
        "        for sub_section in os.listdir(section_path):\n",
        "          sub_section_path = os.path.join(section_path, sub_section)\n",
        "          if os.path.isdir(sub_section_path):\n",
        "            ss_match = re.search(\"([0-9]{2}_)([0-9A-Za-z-]*)\", sub_section)\n",
        "            sub_section_topic = ss_match.group(2)\n",
        "\n",
        "            if os.path.isdir(sub_section_path):\n",
        "              for lecture in os.listdir(sub_section_path):\n",
        "                #print(lecture)\n",
        "                lec_match = re.search(\"([0-9]{2}_)([0-9A-Za-z-]*)(\\.en\\.txt)\",lecture)\n",
        "                lec_title = lec_match.group(2)\n",
        "                with open(os.path.join(sub_section_path, lecture)) as f:\n",
        "                  transcript = f.read()\n",
        "                  mod_transcript = transcript.strip().replace(\"\\n\",\" \")\n",
        "                  course_list.append(course)\n",
        "                  section_list.append(section_title)\n",
        "                  sub_section_list.append(sub_section_topic)\n",
        "                  lec_list.append(lec_title)\n",
        "                  transcript_list.append(mod_transcript)\n",
        "                  #current_df = {'course_title':course, 'section_topic':section_title, 'subsection_topic':sub_section_topic, 'lecture_topic':lec_title,'content':[mod_transcript]})\n",
        "                  #df = df.append(current_df, ignore_index=True)\n",
        "\n",
        "final_dict = {'course_title':course_list, 'section_topic':section_list, 'subsection_topic':sub_section_list, 'lecture_topic':lec_list,'content':transcript_list}\n",
        "final_df = pd.DataFrame.from_dict(final_dict)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(\"Code executed in {} seconds\".format(end-start))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "advanced-methods-reinforcement-learning-finance\n",
            "advanced-portfolio-construction-python\n",
            "applied-data-science-capstone\n",
            "ai-for-everyone\n",
            "art-science-ml\n",
            "attention-models-in-nlp\n",
            "aws-fundamentals-addressing-security-risk\n",
            "aws-fundamentals-going-cloud-native\n",
            "aws-fundamentals-building-serverless-applications\n",
            "bayesian-methods-in-machine-learning\n",
            "basic-data-processing-visualization-python\n",
            "aws-fundamentals-cloud-migration\n",
            "big-data-graph-analytics\n",
            "big-data-introduction\n",
            "big-data-machine-learning\n",
            "big-data-integration-processing\n",
            "big-data-management\n",
            "big-data-project\n",
            "biostats\n",
            "classification-vector-spaces-in-nlp\n",
            "competitive-data-science\n",
            "data-analysis-with-python\n",
            "convolutional-neural-networks-tensorflow\n",
            "convolutional-neural-networks\n",
            "data-products\n",
            "data-science-methodology\n",
            "data-science-project\n",
            "deep-learning-in-computer-vision\n",
            "deploying-machine-learning-models\n",
            "deep-neural-network\n",
            "drug-development\n",
            "drug-commercialization\n",
            "design-thinking-predictive-analytics-data-products\n",
            "drug-discovery\n",
            "exdata\n",
            "dsscapstone\n",
            "feature-engineering\n",
            "fundamentals-machine-learning-in-finance\n",
            "exploratory-data-analysis\n",
            "guided-tour-machine-learning-finance\n",
            "gcp-big-data-ml-fundamentals\n",
            "google-machine-learning\n",
            "hadron-collider-machine-learning\n",
            "intro-tensorflow\n",
            "introduction-portfolio-construction-python\n",
            "intro-to-deep-learning\n",
            "launching-machine-learning\n",
            "introduction-tensorflow\n",
            "language-processing\n",
            "machine-learning-projects\n",
            "machine-learning-duke\n",
            "linear-algebra-machine-learning\n",
            "machine-learning-asset-management-alternative-data\n",
            "meaningful-predictive-modeling\n",
            "machine-learning-with-python\n",
            "ml-clustering-and-retrieval\n",
            "ml-classification\n",
            "ml-foundations\n",
            "multivariate-calculus-machine-learning\n",
            "ml-regression\n",
            "natural-language-processing-tensorflow\n",
            "neural-networks-deep-learning\n",
            "nlp-sequence-models\n",
            "pca-machine-learning\n",
            "open-source-tools-for-data-science\n",
            "practical-machine-learning\n",
            "python-for-data-visualization\n",
            "python-for-applied-data-science-ai\n",
            "r-programming\n",
            "probabilistic-models-in-nlp\n",
            "python-data-analysis\n",
            "python-machine-learning-for-investment-management\n",
            "practical-rl\n",
            "regmods\n",
            "reinforcement-learning-in-finance\n",
            "regression-models\n",
            "repdata\n",
            "rprog\n",
            "reproducible-research\n",
            "statinference\n",
            "sql-data-science\n",
            "statistical-inference\n",
            "sequence-models-in-nlp\n",
            "tensorflow-sequences-time-series-and-prediction\n",
            "what-is-datascience\n",
            "Code executed in 860.9532220363617 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "hhRx1RE6JSxr",
        "outputId": "c2a67ef3-9d64-45a2-abc7-6e5ef86857e4"
      },
      "source": [
        "final_df[final_df.index == 80]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>course_title</th>\n",
              "      <th>section_topic</th>\n",
              "      <th>subsection_topic</th>\n",
              "      <th>lecture_topic</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>ai-for-everyone</td>\n",
              "      <td>what-is-ai</td>\n",
              "      <td>what-is-ai</td>\n",
              "      <td>what-makes-an-ai-company</td>\n",
              "      <td>What makes a company good at AI? Perhaps even ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       course_title  ...                                            content\n",
              "80  ai-for-everyone  ...  What makes a company good at AI? Perhaps even ...\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "TIkU92DtS272",
        "outputId": "1b564528-c1ea-4641-8e6f-7a951ed1a87a"
      },
      "source": [
        "final_df.loc[80,\"content\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What makes a company good at AI? Perhaps even more importantly, what will it take for your company to become great at using AI? I had previously led the Google brain team, and Baidu\\'s AI group, which I respectively helped Google and Baidu become great AI companies. So, what can you do for your company? This is the lesson I had learned to washing the rise of the Internet that I think will be relevant to how all of us navigate the rise of AI. Let\\'s take a look. A lesson we learned from the rise of the Internet was that, if you take your favorite shopping mall. So, my wife and I sometimes shop at Stanford shopping center and you build a website for the Shopping mall. Maybe sell things on the website, that by itself does not turn the shopping mall into an internet company. In fact, a few years ago I was speaking with the CEO of a large retail company who said to me, \"Hey Andrew, I have a website, I sell things in the website.\" Amazon has a website, Amazon sells things on website is the same thing. But of course it wasn\\'t, in the shopping mall with a website isn\\'t the same thing as a first-class internet company. So, what is it that defines an internet company if it isn\\'t just whether or not you sell things on the website? I think an Internet company is a company that does the thing that internet let you do really well. For example, we engage and pervasive AB testing. Meaning we routinely threw up two different versions of website and see which one works better because we can. So, we learn much faster. Whereas in a traditional shopping mall, very difficult to have two shopping malls in two parallel universes and you can only maybe change things around every quarter or every six months. Internet company is since a very short iteration times. You can ship a new product every week or maybe even every day because you can whereas a shopping mall can be redesigned and we are protected only every several months. Internet companies also tend to push decision-making down from the CEO to the engineers and to other specialized rules such that the product managers. This is in contrast to a traditional shopping mall. We can maybe have the CEO just decide all the key decisions and then just everyone does what the CEO says. It turns out that traditional model doesn\\'t work in the internet era because only the engineers and other specialized roles like product managers know enough about the technology and the product and the users to make great decisions. So, these are some of the things that internet companies do in order to make sure they do the things that the internet doesn\\'t do really well. This is a lesson we learned from the internet era. How about the AI era? I think that today, you can take any company and have it use a few neural networks or few deep learning algorithms. That by itself does not turn the accompany into an AI company. Instead, what makes a great AI company, sometimes an AI first company is, are you doing the things that AI lets you do really well? For example, AI companies are very good at strategic data acquisition. This is why many of the large consumer tech companies may have three products that do not monetize and it allows them to acquire data that they can monetize elsewhere. Serve less strategy teams where we would deliberately launch products that do not make any money just for the sake of data acquisition. Thinking through how to get data is a key part of the great AI companies. AI companies sends a unified data warehouses. If you have 50 different databases or 50 different data warehouses under the control of 50 different Vice-Presidents, then there will be impossible for an engineer to get the data into one place so that they can connect the dots and spot the patterns. So, many great AI companies have preemptively invested in bringing the data together into single data warehouse to increase the odds that the teams can connect the dots. Subject of course to privacy guarantees and also to data regulations such as GDPR in Europe. AI companies are very good at spotting automation opportunities. We\\'re very good at saying, Oh! Let\\'s insert the supervised learning algorithm and have an ATP mapping here so that we don\\'t have to have people do these tasks instead we can automate It. AI companies also have many new roles such as the MLE or Machine Learning Engineer and new ways of dividing up tasks among different members of a team. So, for a company to become good at AI means, architecting for company to do the things that AI makes it possible to do really well. Now, for a company that become good at AI does require a process. In fact, 10 years ago, Google and Baidu as well as companies like Facebook and Microsoft that I was not a part of, we\\'re not great AI companies the way they are today. So, how can a company become good at AI? It turns out that becoming good at AI is not a mysterious magical process. Instead there is a systematic process through which many companies, almost any big company can become good at AI. This is the five-step AI transformation playbook that I recommend to companies that want to become effective at using AI. I\\'ll give a brief overview of the playbook here and they\\'re going to detail in a later week. Step one is to execute pilot projects to gain momentum. So, just to a few small projects to get a better sense of what AI can or cannot do and get a better sense of what doing an AI project feels like. This you could do in house or you can also do with an outsource team. But eventually, you then need to do step two which is the building in house AI team and provide broad AI training, not just to the engineers but also to the managers, division leaders and executives and how they think about AI. After doing this or as you\\'re doing this, you have a better sense of what AI is and then is important for many companies to develop an AI strategy. Finally, to align internal and external communications so that all your stakeholders from employees, customers and investors are aligns with how your company is navigating the rise of AI. AI has created tremendous value in the software industry and will continue to do so. It will also create tremendous value outside the software industry. If you can help your company become good at AI, I hope you can play a leading role in creating a lot of this value. It is video you saw what is it that makes a company a good AI company and also briefly the AI transformation playbook which I\\'ll go into much greater detail on in a later week as a road-map for helping companies become great at AI. If you\\'re interested, there is also published online an AI transformation playbook that goes into these five steps in greater detail for you see more of these in the later weeks as well. Now, one of the challenges of doing AI projects such as the pilot projects in step one is understanding what AI can and cannot do. In the next video, I want to show you and give you some examples of what AI can and cannot do, to help you better select projects AI that there may be effective for your company. That\\'s gone to the next video.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1u6DGQJA5E8"
      },
      "source": [
        "### Writing out the dataframe to CSV so that I dont have to keep running the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooRLfcfgZKqH"
      },
      "source": [
        "final_df.to_csv(\"/gdrive/MyDrive/Text_Summarizer/structured_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "CpI8QlzZBewS",
        "outputId": "422ff1c7-3818-44e7-e4ef-c94be1c18ef3"
      },
      "source": [
        "read_df = pd.read_csv(\"/gdrive/MyDrive/Text_Summarizer/structured_df.csv\", index_col=0)\n",
        "read_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>course_title</th>\n",
              "      <th>section_topic</th>\n",
              "      <th>subsection_topic</th>\n",
              "      <th>lecture_topic</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>advanced-methods-reinforcement-learning-finance</td>\n",
              "      <td>other-applications-of-reinforcement-learning-p...</td>\n",
              "      <td>lesson-1</td>\n",
              "      <td>trades-quotes-and-order-flow</td>\n",
              "      <td>All right. Let's first talk about what type of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advanced-methods-reinforcement-learning-finance</td>\n",
              "      <td>other-applications-of-reinforcement-learning-p...</td>\n",
              "      <td>lesson-1</td>\n",
              "      <td>electronic-markets-and-lob</td>\n",
              "      <td>So, so far in this specialization our examples...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>advanced-methods-reinforcement-learning-finance</td>\n",
              "      <td>other-applications-of-reinforcement-learning-p...</td>\n",
              "      <td>lesson-1</td>\n",
              "      <td>welcome</td>\n",
              "      <td>Welcome to week four of our course on events t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>advanced-methods-reinforcement-learning-finance</td>\n",
              "      <td>other-applications-of-reinforcement-learning-p...</td>\n",
              "      <td>lesson-1</td>\n",
              "      <td>limit-order-book</td>\n",
              "      <td>Now, let's talk a bit more about the Limit Ord...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>advanced-methods-reinforcement-learning-finance</td>\n",
              "      <td>other-applications-of-reinforcement-learning-p...</td>\n",
              "      <td>lesson-1</td>\n",
              "      <td>lob-modeling</td>\n",
              "      <td>Now, after we talked about what the LOB is, le...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      course_title  ...                                            content\n",
              "0  advanced-methods-reinforcement-learning-finance  ...  All right. Let's first talk about what type of...\n",
              "1  advanced-methods-reinforcement-learning-finance  ...  So, so far in this specialization our examples...\n",
              "2  advanced-methods-reinforcement-learning-finance  ...  Welcome to week four of our course on events t...\n",
              "3  advanced-methods-reinforcement-learning-finance  ...  Now, let's talk a bit more about the Limit Ord...\n",
              "4  advanced-methods-reinforcement-learning-finance  ...  Now, after we talked about what the LOB is, le...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC3M4bcPaqYI"
      },
      "source": [
        "## When size of input data id very large: Use TF-Data (text_dataset_from_directory) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99ewlAhNLSPV"
      },
      "source": [
        "# Reading Files with TF-Data\n",
        "dir = \"/gdrive/MyDrive/Text_Summarizer/Data\"\n",
        "raw_data = preprocessing.text_dataset_from_directory(dir)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6j8o9ulN-kd",
        "outputId": "9530c144-804b-4210-c324-dbfa83d0283e"
      },
      "source": [
        "for text_batch, label_batch in raw_data.take(1):\n",
        "  for i in range(5):\n",
        "    print(\"Text: \", text_batch.numpy()[i][:200], '...')\n",
        "    print(\"Lecture:\", label_batch.numpy()[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:  b\"Welcome to the fourth week of this course. By now, you've seen forward propagation and\\nback propagation in the context of a neural network, with a single hidden\\nlayer, as well as logistic regression, \" ...\n",
            "Lecture: 0\n",
            "Text:  b\"We've all been hearing that deep\\nneural networks work really well for a lot of problems, and it's not just that\\nthey need to be big neural networks, is that specifically, they need to be\\ndeep or to ha\" ...\n",
            "Lecture: 0\n",
            "Text:  b\"When implementing a deep neural network,\\none of the debugging tools I often use to check the correctness of my code\\nis to pull a piece of paper, and just work through the dimensions and\\nmatrix I'm wor\" ...\n",
            "Lecture: 0\n",
            "Text:  b\"being effective in developing your deep neural Nets requires that you not only organize your parameters well but also your hyper parameters so what are hyper parameters let's take a look so the parame\" ...\n",
            "Lecture: 0\n",
            "Text:  b\"So, what does deep learning have to do with the brain? At the risk of giving away the punchline, I would say not a whole lot. But let's take a quick look at why people keep making the analogy between \" ...\n",
            "Lecture: 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}